# Auto_log 详细规范 (Detailed Specification)

> **用途**：补充核心模板 `auto_log_template.md`，提供详细的信息提取规则、质量检查标准和常见问题处理方案。
> **按需引用**：仅在需要详细规范时查阅，不作为常驻模板。

---

## 信息提取规则详解

### 1. 决策标记提取

从会话历史中识别并提取以下明确标记：

#### 标准格式标记

```markdown
[DECISION_LOG]
决策内容：[具体决策]
决策依据：[规则编号/标准]
置信度：[certain/high/medium/low]
[/DECISION_LOG]
```

#### 阶段转换标记

```markdown
[PHASE_TRANSITION]P1→P2[/PHASE_TRANSITION]
[PHASE_TRANSITION]P2→P3[/PHASE_TRANSITION]
[PHASE_TRANSITION]P3→P4[/PHASE_TRANSITION]
```

#### 自动化模式标记

```markdown
[AUTOMATION_MODE: true]
[AUTOMATION_MODE: false]
```

#### 覆盖率目标标记

```markdown
[COVERAGE_TARGET: 85%]
[COVERAGE_TARGET: 90%]
```

#### API 错误标记

```markdown
[API_ERROR]
时间：[timestamp]
工具：[tool_name]
错误：[error_message]
应对：[处理方法]
[/API_ERROR]
```

### 2. TodoList 状态追踪

TodoList 工具的状态变化可反映任务执行进度：

```json
// Pending → In Progress
{"content": "创建 plan.md", "status": "in_progress"}

// In Progress → Completed
{"content": "创建 plan.md", "status": "completed"}
```

**提取逻辑**：
- 统计每个 todo 从 pending → in_progress → completed 的时间
- 记录阶段内的 todo 完成率
- 识别未完成的 todo（遗留问题）

### 3. 隐式决策识别

除显式标记外，还需从以下对话模式中提取决策：

#### 工具调用记录

```
[全自动模式] 调用 plan-down skill 生成 plan.md...
→ 提取决策：使用 plan-down skill
→ 置信度：certain（强制规则）
→ 依据：G11
```

#### 阶段推进声明

```
P1 分析完成，自动进入 P2 阶段
→ 提取决策：阶段推进 P1→P2
→ 置信度：high
→ 依据：automation_mode=true + P1 无阻塞
```

#### 质量检查结果

```
codex 检查发现 4 个问题：
- SQL注入 (Critical) → ✅ 自动修复
- 异常处理 (Medium) → ✅ 自动修复
- 变量命名 (Low) → ✅ 自动修复
- 业务逻辑 (Medium) → ⏭️ 跳过
→ 提取 4 条修复决策，各自有依据和结果
```

### 4. 时间戳提取规则

**优先级顺序**：
1. 会话历史中的系统时间戳（如果有）
2. 用户消息时间戳
3. 任务开始/结束时的时间戳
4. 生成日志时的当前时间作为兜底

**格式统一**：
- 标准格式：`YYYY-MM-DD HH:MM:SS`
- 示例：`2025-01-15 14:30:45`

### 5. 文件清单统计

**源代码统计**：
- 新增文件：计算总行数（不含空行和注释）
- 修改文件：计算 +N/-M 行数变化

**测试代码统计**：
- 新增测试文件：计算总行数
- 测试覆盖率：从 codex 或测试工具输出中提取

**文档统计**：
- PROJECTWIKI.md：列出更新的章节
- CHANGELOG.md：标注更新的版本号或 [Unreleased]
- 其他文档：列出新增/修改的文件名

---

## P4 未触发原因详细模板

### 使用场景

当任务完成后 **P4 状态为 ⚠️未触发** 时，必须在"阶段流转表"中说明原因。

### 常见原因分类

#### 分类 1：P3 执行中问题已修复

**场景**：
- P3 执行过程中发现问题
- 问题在当前阶段内解决
- 无遗留错误进入 P4

**说明模板**：
```markdown
**P4 未触发原因**：
- ✅ P3 执行中所有问题已在过程中修复，无遗留错误
- 具体修复：
  - 问题1：[描述] → [修复方法]
  - 问题2：[描述] → [修复方法]
- 验证结果：[测试通过/质量检查通过]
```

#### 分类 2：测试失败为测试代码问题

**场景**：
- simple-gemini 生成的测试代码有问题
- codex 在验证阶段发现并修复
- 业务逻辑代码本身没有问题

**说明模板**：
```markdown
**P4 未触发原因**：
- ✅ 测试失败为测试代码问题而非业务逻辑问题，已在测试生成阶段修复
- 测试问题：
  - [测试文件名]：[问题描述]
  - 修复：[修复方法]
- 验证结果：测试代码修复后全部通过
```

#### 分类 3：代码质量检查通过

**场景**：
- codex 双轮验证未发现 Critical/High 级别问题
- 仅有 Medium/Low 问题且已自动修复或跳过
- 代码质量达标，无需进入 P4

**说明模板**：
```markdown
**P4 未触发原因**：
- ✅ 代码质量检查未发现 Critical/High 级别问题
- 质量检查结果：
  - codereview 工作流：✅ 通过（0 个 Critical/High 问题）
  - codex CLI 深度分析：✅ 通过（0 个 Critical/High 问题）
  - Medium 问题：[N] 个（已自动修复）
  - Low 问题：[N] 个（已修复/已跳过）
```

#### 分类 4：其他原因

**场景**：任务性质决定不需要 P4

**说明模板**：
```markdown
**P4 未触发原因**：
- ✅ 其他原因：[具体说明]
- 示例：
  - "本任务为纯文档生成，不涉及代码执行，无 P4 触发条件"
  - "任务为静态代码重构，已通过完整测试套件验证"
```

### 强制要求

- ❌ **绝对禁止**：P4 状态为 ⚠️未触发 时，不提供任何说明
- ✅ **强制要求**：必须从上述 4 类中选择至少 1 类，提供具体说明
- ✅ **透明性**：如有多个原因，可组合说明

---

## 质量检查清单（完整版）

### 必选章节完整性检查 (7/7)

- [ ] **1. 任务元信息** (Task Metadata)
  - [ ] 任务 ID 已填写（continuation_id 或生成的唯一 ID）
  - [ ] 执行模式确认为 automation_mode=true
  - [ ] 用户初始请求完整记录
  - [ ] 开始时间、结束时间、总耗时均已填写

- [ ] **2. 执行摘要** (Executive Summary)
  - [ ] 任务目标清晰列出（至少 1 项）
  - [ ] 最终结果包含完成度、代码生成、测试覆盖率、文档更新、质量检查
  - [ ] 所有指标都有具体数值（非占位符）

- [ ] **3. 阶段流转表** (Phase Transitions)
  - [ ] P1/P2/P3 状态均已标注（✅/⚠️/❌）
  - [ ] P4 状态已标注（⚠️未触发/✅已完成）
  - [ ] **P4 未触发时必须提供原因说明**（见上节）
  - [ ] 每个阶段的耗时已填写
  - [ ] 每个阶段的关键输出已记录

- [ ] **4. 自动决策记录** (Automated Decisions)
  - [ ] 所有决策都有唯一 ID（P{阶段}-{序号}）
  - [ ] 每个决策包含：内容、时间、置信度、依据、影响范围
  - [ ] 置信度等级合理（certain/high/medium/low）
  - [ ] 决策依据可追溯（引用规则编号或标准）

- [ ] **5. 质量指标** (Quality Metrics)
  - [ ] 测试覆盖率有目标值 vs 实际值对比
  - [ ] 代码质量 5 维度表格完整填写
  - [ ] 测试执行结果包含总数、通过、失败、跳过、通过率

- [ ] **6. 文件清单** (File Inventory)
  - [ ] 源代码统计准确（新增/修改文件数和行数）
  - [ ] 测试代码统计准确
  - [ ] 文档更新记录完整（PROJECTWIKI.md, CHANGELOG.md）
  - [ ] 配置文件变更已列出（如有）

- [ ] **7. 结论与建议** (Conclusion)
  - [ ] 任务完成情况说明清晰
  - [ ] 自动化效果评估已填写
  - [ ] 后续建议明确（如无，填写"无"）
  - [ ] 遗留问题列出（如无，填写"无遗留问题"）

### 可选章节检查

- [ ] **API/工具失败记录**（如有 API 错误则必填）
  - [ ] 每个失败记录包含时间、工具、错误、应对、影响

### 内容质量检查 (20 项)

1. [ ] 所有 `[占位符]` 已替换为实际值（不允许出现 `[N]`, `[X]%`, `[描述]` 等）
2. [ ] P4 未触发时提供了明确且具体的原因说明
3. [ ] 决策记录中的置信度与实际情况相符
4. [ ] 决策依据引用了具体的规则编号（如 G9, G11, P3 前置条件）
5. [ ] 覆盖率有目标值和实际值的对比（如 "85% vs 87%"）
6. [ ] 文件统计数量准确（与实际文件操作一致）
7. [ ] 时间戳格式统一（YYYY-MM-DD HH:MM:SS）
8. [ ] 状态图标使用统一（✅/⚠️/❌）
9. [ ] 代码路径使用反引号包裹（如 `` `src/main.py` ``）
10. [ ] 阶段耗时合理（总耗时 = 各阶段耗时之和）
11. [ ] 决策 ID 连续且无重复（P1-001, P1-002, ...）
12. [ ] 质量指标的评分合理（如安全问题多，安全维度评分应低）
13. [ ] 测试通过率计算正确（通过数 / 总数 × 100%）
14. [ ] 文件清单中的行数统计合理（不出现负数或异常大的数字）
15. [ ] 自动化效果评估客观真实（不夸大成效）
16. [ ] 后续建议具体可行（避免空泛建议）
17. [ ] 遗留问题清晰描述（包含问题现象和影响）
18. [ ] 决策内容简洁明确（避免冗长描述）
19. [ ] 备选方案说明充分（为何未选择其他方案）
20. [ ] 影响范围描述准确（列出具体受影响的文件/模块）

### 格式规范检查 (10 项)

1. [ ] Markdown 格式正确，无语法错误
2. [ ] 表格对齐，列宽一致
3. [ ] 代码块使用正确的语言标记（```markdown, ```python, ```yaml）
4. [ ] 列表层级正确（不混用 `-` 和 `*`）
5. [ ] 标题层级合理（不跳级，如 ## 后不直接跟 ####）
6. [ ] 空行使用一致（章节之间有空行分隔）
7. [ ] 链接格式正确（如有外部链接，使用 `[文本](URL)` 格式）
8. [ ] 强调标记一致（使用 `**粗体**`，不混用 `__粗体__`）
9. [ ] 文件末尾有换行符
10. [ ] 无多余空格或制表符

### 一致性检查 (5 项)

1. [ ] 执行摘要中的完成度与结论中的完成度一致
2. [ ] 阶段流转表中的状态与执行摘要中的描述一致
3. [ ] 质量指标中的覆盖率与执行摘要中的覆盖率一致
4. [ ] 文件清单中的统计与决策记录中提到的文件一致
5. [ ] 后续建议与遗留问题相呼应（遗留问题的解决建议应在后续建议中）

---

## FAQ（常见问题处理）

### 1. 任务中途失败怎么办？

**场景**：
- 任务执行过程中遇到无法自动解决的问题
- 任务被用户中断
- 环境错误导致无法继续

**处理方法**：
1. 在"执行摘要"中标注任务未完成
2. 在"完成度"中填写实际完成百分比（如 "60%"）
3. 在"阶段流转表"中标注失败阶段为 ❌
4. 在"结论与建议"中说明失败原因
5. 在"遗留问题"中列出未完成的任务项

**示例**：
```markdown
## 执行摘要

### 最终结果
- **完成度**: 60% (任务未完成)
- **失败原因**: 环境缺失 Python 3.11，无法继续执行

## 结论与建议

### 任务完成情况
- **完成度**: 60%
- **未完成项**:
  - P3 执行方案：代码生成完成，但测试执行失败
  - 测试代码生成：未开始
- **偏差说明**: 因环境问题提前终止

### 遗留问题
- Python 3.11 环境缺失，需用户安装后重新执行
- 已生成的代码未经测试验证
```

### 2. API 失败如何记录？

**场景**：
- 调用 MCP 工具失败（如 mcp__zen__clink 返回 401 错误）
- 外部 API 调用超时
- 模型 API 配额不足

**处理方法**：
1. 在"可选章节"中添加 **API/工具失败记录**
2. 记录每个失败的详细信息
3. 在"自动决策记录"中记录应对策略

**示例**：
```markdown
## API/工具失败记录

### 失败 1
- **时间**: 2025-01-15 14:35:20
- **工具**: mcp__zen__clink
- **错误**: 401 PERMISSION_DENIED - API key suspended
- **应对**: 切换到备用模型 gemini-2.5-pro
- **影响**: 延迟 5 分钟，任务最终成功完成

## 自动决策记录

### 决策 P2-003
- **决策内容**: gemini-2.0-flash-thinking-exp 不可用，自动切换到 gemini-2.5-pro
- **决策时间**: 2025-01-15 14:35:25
- **置信度**: high
- **决策依据**: API 错误自动降级策略
- **影响范围**: plan-down skill 的模型选择
- **备选方案**: 使用 codex（已拒绝，codex 需先启动 CLI）
```

### 3. 覆盖率未达标怎么处理？

**场景**：
- 实际覆盖率 < coverage_target
- 实际覆盖率 < 70% (最低阈值)

**处理方法**：

**情况 1：实际覆盖率 ≥ 70% 但 < coverage_target**
```markdown
## 质量指标

### 测试覆盖率
- **目标值**: 85%
- **实际值**: 78%
- **达标状态**: ⚠️ 未达标（但高于最低阈值 70%）

## 结论与建议

### 后续建议
- 补充测试用例以达到 85% 覆盖率目标
- 重点覆盖未测试的边界条件和异常处理路径
```

**情况 2：实际覆盖率 < 70% (严重不足)**
```markdown
## 质量指标

### 测试覆盖率
- **目标值**: 85%
- **实际值**: 62%
- **达标状态**: ❌ 严重不足（低于最低阈值 70%）

## 结论与建议

### 任务完成情况
- **完成度**: 80%
- **未完成项**: 测试覆盖率未达标（62% < 70%）

### 后续建议
- **强制要求**：补充测试用例至少达到 70% 覆盖率
- 优先覆盖核心业务逻辑和关键路径
- 使用覆盖率工具生成覆盖率报告，定位未覆盖代码
```

### 4. 如何确保信息提取完整？

**方法**：
1. 使用本文档第一节的信息提取规则
2. 逐条核对会话历史，确保所有标记都已识别
3. 对比 TodoList 状态变化，确保所有任务都已记录
4. 使用质量检查清单验证

**自动化辅助**：
- 使用正则表达式匹配标记（如 `\[DECISION_LOG\].*?\[/DECISION_LOG\]`）
- 解析 TodoList 工具的 JSON 输出
- 统计会话历史中的阶段标签（P1, P2, P3, P4）

### 5. 决策 ID 如何生成？

**规则**：
- 格式：`P{阶段}-{序号}`
- 阶段：P1, P2, P3, P4
- 序号：从 001 开始，连续递增

**示例**：
```
P1-001  # P1 阶段第 1 个决策
P1-002  # P1 阶段第 2 个决策
P2-001  # P2 阶段第 1 个决策
P2-002  # P2 阶段第 2 个决策
P3-001  # P3 阶段第 1 个决策
```

**注意事项**：
- 同一阶段内，序号连续无跳跃
- 不同阶段的序号独立计数
- 如有阶段重复进入（如 P3 → P1 → P2 → P3），第二次进入 P3 的决策继续使用 P3-XXX

### 6. 如何处理多轮修复（P3 → P4 → P3 循环）？

**场景**：
- P3 执行后进入 P4 修复
- P4 修复完成，重新回到 P3 验证
- 可能多次循环

**处理方法**：
1. 在"阶段流转表"中记录所有阶段状态
2. 在"自动决策记录"中标注每次修复的决策
3. 在"执行摘要"中说明循环次数

**示例**：
```markdown
## 阶段流转表

| 阶段 | 状态 | 耗时 | 关键输出 | 说明 |
|------|------|------|---------|------|
| P1 分析问题 | ✅ | 5 分钟 | 需求分析 | 完成 |
| P2 制定方案 | ✅ | 10 分钟 | plan.md | 完成 |
| P3 执行方案 | ⚠️ | 20 分钟 | 代码生成 | 第 1 次执行，发现 2 个问题 |
| P4 错误处理 | ✅ | 8 分钟 | 修复代码 | 第 1 次修复 |
| P3 执行方案 | ⚠️ | 5 分钟 | 回归测试 | 第 2 次执行，发现 1 个问题 |
| P4 错误处理 | ✅ | 3 分钟 | 修复代码 | 第 2 次修复 |
| P3 执行方案 | ✅ | 3 分钟 | 最终验证 | 第 3 次执行，全部通过 |

## 执行摘要

### 最终结果
- **完成度**: 100%
- **P3 → P4 循环次数**: 2 次
- **修复问题总数**: 3 个（第 1 轮 2 个，第 2 轮 1 个）
```

### 7. 自动化模式与交互模式的区别如何体现？

**automation_mode=true（自动化模式）**：
- 所有决策自动执行，无需用户确认
- 决策记录中强调"自动决策"
- 置信度通常为 certain/high

**automation_mode=false（交互模式）**：
- 不生成 auto_log.md
- 如需记录，则标注为"交互日志"
- 决策记录中包含用户确认环节

**auto_log.md 专属特征**：
- 只在 automation_mode=true 时生成
- 不记录用户确认环节（因为没有）
- 所有决策都有依据和置信度

---

## 版本历史

- **v1.0** (2025-01-15): 初始版本，提取自备份模板的详细内容
